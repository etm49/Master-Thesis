{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6133ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from surprise import BaselineOnly, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings = pd.read_csv(\"../data/reducedUserRatings.csv\", index_col=0) # issues with outliers and usernames already fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naturalNumber(val):\n",
    "    \"\"\"Find all non-natural number ratings\"\"\"\n",
    "    return round(val) ==val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdeec7",
   "metadata": {},
   "source": [
    "## ADDITION EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9872378",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings[\"isNatural\"] = userRatings.Rating.apply(lambda x: naturalNumber(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=userRatings,x=\"isNatural\",hue=\"isNatural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee984e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings[\"Rating\"] = userRatings.Rating.apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of users \n",
    "userRatings.reducedUsername.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items\n",
    "userRatings.BGGId.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distplot(figRows,figCols,xSize, ySize, data, features, colors, kde=True, bins=None):\n",
    "    f, axes = plt.subplots(figRows, figCols, figsize=(xSize, ySize))\n",
    "    \n",
    "    features = np.array(features).reshape(figRows, figCols)\n",
    "    colors = np.array(colors).reshape(figRows, figCols)\n",
    "    \n",
    "    for row in range(figRows):\n",
    "        for col in range(figCols):\n",
    "            if (figRows == 1 and figCols == 1) :\n",
    "                axesplt = axes\n",
    "            elif (figRows == 1 and figCols > 1) :\n",
    "                axesplt = axes[col]\n",
    "            elif (figRows > 1 and figCols == 1) :\n",
    "                axesplt = axes[row]\n",
    "            else:\n",
    "                axesplt = axes[row][col]\n",
    "            plot = sns.distplot(data[features[row][col]], color=colors[row][col], bins=bins, ax=axesplt, kde=kde, hist_kws={\"edgecolor\":\"k\"})\n",
    "            plot.set_xlabel(features[row][col],fontsize=20)\n",
    "\n",
    "def scatterplot(rowFeature, colFeature, data):\n",
    "    f, axes = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        \n",
    "    plot=sns.scatterplot(x=rowFeature, y=colFeature, data=data, ax=axes)\n",
    "    plot.set_xlabel(rowFeature,fontsize=20)\n",
    "    plot.set_ylabel(colFeature,fontsize=20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = sns.color_palette(palette='Set1', n_colors=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc085a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating Distribution\n",
    "\n",
    "distplot(1, 1, 10, 7, data=userRatings, features=['Rating'], colors=['blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7488b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_products_Ratings = userRatings.groupby('BGGId')['Rating']\n",
    "\n",
    "ratings_products = pd.DataFrame(groupby_products_Ratings.count().clip(upper=30))\n",
    "ratings_products.rename(columns={\"Rating\": \"Rating_Count\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(groupby_products_Ratings.count() ==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "(groupby_products_Ratings.count() ==1).sum()/userRatings.BGGId.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Distribution grouped by Products\n",
    "distplot(1, 1, 10, 7, data=pd.DataFrame(groupby_products_Ratings.count()).rename(columns={\"Rating\": \"Rating_Count\"}), features=['Rating_Count'], colors=['green'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Rating Count Distribution grouped by Products upper 30\n",
    "distplot(1, 1, 10, 7, data=ratings_products, features=['Rating_Count'], colors=['green'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aab637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Rating Count Distribution grouped by Products\n",
    "distplot(1, 1, 10, 7, data=pd.DataFrame(groupby_products_Ratings.count().clip(upper=10)).rename(columns={\"Rating\": \"Rating_Count\"}), features=['Rating_Count'], colors=['green'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81611adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_users_Ratings = userRatings.groupby('reducedUsername')['Rating']\n",
    "rating_users = pd.DataFrame(groupby_users_Ratings.count().clip(lower=1, upper=100))\n",
    "rating_users.rename(columns={\"Rating\": \"Rating_Count\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cabe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(groupby_users_Ratings.count() ==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "(groupby_users_Ratings.count() ==1).sum()/userRatings.reducedUsername.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55274807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Rating Count Distribution grouped by Users\n",
    "distplot(1, 1, 10, 7, data=pd.DataFrame(groupby_users_Ratings.count()).rename(columns={\"Rating\": \"Rating_Count\"}), features=['Rating_Count'], colors=['orange'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Rating Count Distribution grouped by Users\n",
    "distplot(1, 1, 10, 7, data=rating_users, features=['Rating_Count'], colors=['orange'], kde=False, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Rating Count Distribution grouped by Users\n",
    "distplot(1, 1, 10, 7, data=pd.DataFrame(groupby_users_Ratings.count().clip(upper=20)).rename(columns={\"Rating\": \"Rating_Count\"}), features=['Rating_Count'], colors=['orange'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(userRatings.groupby('BGGId')['Rating'].mean())\n",
    "ratings.rename(columns={\"Rating\": \"Rating_Mean\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Rating Distribution grouped by Products\n",
    "distplot(1, 1, 10, 7, data=ratings, features=['Rating_Mean'], colors=['brown'], kde=False, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['Rating_Count'] = userRatings.groupby('BGGId')['Rating'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Rating - Rating Count Distribution grouped by Products\n",
    "scatterplot('Rating_Mean', 'Rating_Count', data=ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d067754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Rating Distribution grouped by Users\n",
    "ratings = pd.DataFrame(userRatings.groupby('reducedUsername')['Rating'].mean())\n",
    "ratings.rename(columns={\"Rating\": \"Rating_Mean\"}, inplace=True)\n",
    "distplot(1, 1, 10, 7, data=ratings, features=['Rating_Mean'], colors=['brown'], kde=False, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Rating - Rating Count Distribution grouped by Users\n",
    "ratings['Rating_Count'] = userRatings.groupby('reducedUsername')['Rating'].count()\n",
    "scatterplot('Rating_Mean', 'Rating_Count', data=ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3fbbb",
   "metadata": {},
   "source": [
    "# BASIC CF AS IMPLEMETED IN [SURPRISE](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly, Dataset, Reader, dataset\n",
    "from surprise.model_selection import cross_validate,RandomizedSearchCV,GridSearchCV, KFold\n",
    "from surprise import KNNWithMeans,KNNWithZScore,SVD,KNNBaseline,KNNBasic\n",
    "from surprise import accuracy\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe88ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep a subset of the data for final testing\n",
    "trainset, testset = train_test_split(userRatings, test_size=.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "traindata = Dataset.load_from_df(trainset[[\"reducedUsername\", \"BGGId\", \"Rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.has_been_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we cannot do pipeline Gridsearch, we will fix the cross valdiation folds for model comparison\n",
    "cv = KFold(n_splits=3, shuffle=False, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e53ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {\"KNNBasic_pearson_user\":KNNBasic(sim_options={'name':'pearson' , 'user_based':True}),\n",
    "             \"KNNBasic_pearson_item\":KNNBasic(sim_options={'name':'pearson' , 'user_based':False}),\n",
    "             \"KNNBasic_cosine_user\":KNNBasic(sim_options={'name':'cosine' , 'user_based':True}),\n",
    "             \"KNNBasic_cosine_item\":KNNBasic(sim_options={'name':'cosine' , 'user_based':False}),\n",
    "             \"KNNBasic_MSD_user\":KNNBasic(sim_options={'name':'MSD' , 'user_based':True}),\n",
    "             \"KNNBasic_MSD_item\":KNNBasic(sim_options={'name':'MSD' , 'user_based':False}),\n",
    "             \"KNNBasic_pearson_baseline_user\":KNNBasic(sim_options={'name':'pearson_baseline' , 'user_based':True}),\n",
    "             \"KNNBasic_pearson_baseline_item\":KNNBasic(sim_options={'name':'pearson_baseline' , 'user_based':False}),\n",
    "              \n",
    "             \"KNNWithZScore_pearson_user\":KNNWithZScore(sim_options={'name':'pearson' , 'user_based':True}),\n",
    "             \"KNNWithZScore_pearson_item\":KNNWithZScore(sim_options={'name':'pearson' , 'user_based':False}),\n",
    "             \"KNNWithZScore_cosine_user\":KNNWithZScore(sim_options={'name':'cosine' , 'user_based':True}),\n",
    "             \"KNNWithZScore_cosine_item\":KNNWithZScore(sim_options={'name':'cosine' , 'user_based':False}),\n",
    "             \"KNNWithZScore_MSD_user\":KNNWithZScore(sim_options={'name':'MSD' , 'user_based':True}),\n",
    "             \"KNNWithZScore_MSD_item\":KNNWithZScore(sim_options={'name':'MSD' , 'user_based':False}),\n",
    "             \"KNNWithZScore_pearson_baseline_user\":KNNWithZScore(sim_options={'name':'pearson_baseline' , 'user_based':True}),\n",
    "             \"KNNWithZScore_pearson_baseline_item\":KNNWithZScore(sim_options={'name':'pearson_baseline' , 'user_based':False}),\n",
    "\n",
    "             \"KNNWithMeans_pearson_user\":KNNWithMeans(sim_options={'name':'pearson' , 'user_based':True}),\n",
    "             \"KNNWithMeans_pearson_item\":KNNWithMeans(sim_options={'name':'pearson' , 'user_based':False}),\n",
    "             \"KNNWithMeans_cosine_user\":KNNWithMeans(sim_options={'name':'cosine' , 'user_based':True}),\n",
    "             \"KNNWithMeans_cosine_item\":KNNWithMeans(sim_options={'name':'cosine' , 'user_based':False}),\n",
    "             \"KNNWithMeans_MSD_user\":KNNWithMeans(sim_options={'name':'MSD' , 'user_based':True}),\n",
    "             \"KNNWithMeans_MSD_item\":KNNWithMeans(sim_options={'name':'MSD' , 'user_based':False}),\n",
    "             \"KNNWithMeans_pearson_baseline_user\":KNNWithMeans(sim_options={'name':'pearson_baseline' , 'user_based':True}),\n",
    "             \"KNNWithMeans_pearson_baseline_item\":KNNWithMeans(sim_options={'name':'pearson_baseline' , 'user_based':False}),\n",
    "              \n",
    "             \"KNNBaseline_pearson_user\":KNNBaseline(sim_options={'name':'pearson' , 'user_based':True}),\n",
    "             \"KNNBaseline_pearson_item\":KNNBaseline(sim_options={'name':'pearson' , 'user_based':False}),\n",
    "             \"KNNBaseline_cosine_user\":KNNBaseline(sim_options={'name':'cosine' , 'user_based':True}),\n",
    "             \"KNNBaseline_cosine_item\":KNNBaseline(sim_options={'name':'cosine' , 'user_based':False}),\n",
    "             \"KNNBaseline_MSD_user\":KNNBaseline(sim_options={'name':'MSD' , 'user_based':True}),\n",
    "             \"KNNBaseline_MSD_item\":KNNBaseline(sim_options={'name':'MSD' , 'user_based':False}),\n",
    "             \"KNNBaseline_pearson_baseline_user\":KNNBaseline(sim_options={'name':'pearson_baseline' , 'user_based':True}),\n",
    "             \"KNNBaseline_pearson_baseline_item\":KNNBaseline(sim_options={'name':'pearson_baseline' , 'user_based':False}),\n",
    "             \n",
    "             \"SVD\":SVD( n_epochs=50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953dd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the metrics are the average scores over the cross validation folds\n",
    "results = pd.DataFrame(index= model_list.keys(), columns=['test_rmse','test_mae','fit_time','test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,v in enumerate(model_list):\n",
    "    dictonary = cross_validate(model_list[v], traindata, cv=cv, verbose=True,)\n",
    "    for key in dictonary.keys():\n",
    "        results.loc[v,key] = np.mean((dictonary[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ded240",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['test_rmse','test_mae'], ascending=True).style.bar(color='#d65f5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e08a54",
   "metadata": {},
   "source": [
    "## Gridsearch for tuning some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788cc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\"KNNBasic\":KNNBasic,\n",
    "             \"KNNWithZScore\":KNNWithZScore,\n",
    "             \"KNNWithMeans\":KNNWithMeans,\n",
    "             \"SVD\": SVD,\n",
    "              \"KNNBaseline\":KNNBaseline\n",
    "             }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b24d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = [\"pearson\",\n",
    "                \"cosine\",\n",
    "                \"MSD\",\n",
    "                \"pearson_baseline\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538058cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\"KNNBasic\":{\n",
    "                            'k': [101],\n",
    "                            'sim_options': {\n",
    "                                'name': similarities,\n",
    "                                'min_support': [5, 10, 15],\n",
    "                                'user_based': [False, True],\n",
    "                                'shrinkage': [0, 10,100]\n",
    "                            },\n",
    "                        },\n",
    "              \"KNNWithZScore\":{\n",
    "                            'k': [101],\n",
    "                            'sim_options': {\n",
    "                                'name': similarities,\n",
    "                                'min_support': [5, 10, 15],\n",
    "                                'user_based': [False, True],\n",
    "                                'shrinkage': [0, 10,100]\n",
    "                            },\n",
    "                        },\n",
    "                \"KNNWithMeans\":{\n",
    "                            'k': [101],\n",
    "                            'sim_options': {\n",
    "                                'name': similarities,\n",
    "                                'min_support': [5, 10, 15],\n",
    "                                'user_based': [False, True],\n",
    "                                'shrinkage': [0, 10,100]\n",
    "                            },\n",
    "                        },\n",
    "              \"KNNBaseline\":{\n",
    "                            'k': [101],\n",
    "                            'sim_options': {\n",
    "                                'name': similarities,\n",
    "                                'min_support': [5, 10, 15],\n",
    "                                'user_based': [False, True],\n",
    "                                'shrinkage': [0, 10,100]\n",
    "                            },\n",
    "                          \"bsl_options\" : {\n",
    "                                    \"method\": [\"sgd\",'als'],\n",
    "                                    'reg_i' :[0,5,10],\n",
    "                                    'reg_u' : [0,5,10],\n",
    "                                    'reg': [0.00005, 0.005,0.5],\n",
    "                                    \"learning_rate\": [0.00005, 0.005,0.5],\n",
    "                                    'n_epochs': [20]\n",
    "                                }\n",
    "                        },\n",
    "              \"SVD\":{\"n_epochs\": [5, 10], \"lr_all\": [0.002, 0.005], \"reg_all\": [0.4, 0.6], \"biased\": [False, True]}\n",
    "            \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3855c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color=None):\n",
    "    '''Print to track progress'''\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8434384",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec26eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f93c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in model_dict:\n",
    "    printmd(f\"**{i}**\", color=\"blue\")\n",
    "    model = model_dict[i]\n",
    "    parameters = param_dict[i]\n",
    "    \n",
    "    gs = GridSearchCV(model, parameters, measures=[\"rmse\", \"mae\"], cv=cv)\n",
    "    gs.fit(traindata)\n",
    "    sub = pd.DataFrame.from_dict(gs.cv_results)\n",
    "    sub[\"model\"] = i\n",
    "    gs_results = pd.concat([gs_results,sub])\n",
    "    #display(gs_results.tail(4))\n",
    "    printmd(\"**Done**\", color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next questions to address\n",
    "# Why does cosine similarity result in zero division for small minimum support like 1?\n",
    "\n",
    "# Can and should we manually adjust the search space for minimum data based on training data distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5d893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9b956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c41a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209bb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36c058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bcdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036d3ca",
   "metadata": {},
   "source": [
    "#### Lets build a pipeline for hyperparameter tuning and model selection all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from enum import Enum\n",
    "# class Model(Enum):\n",
    "#     KNNWithZScore='z standrdized CF'\n",
    "#     KNNWithMeans='baseline centered CF'\n",
    "#     all= 'best model'\n",
    "\n",
    "\n",
    "\n",
    "# model_list = [e for e in Model if e != Model.all]\n",
    "# model_instances = []\n",
    "# params = []\n",
    "\n",
    "# num_folds = 5  # Hard coded\n",
    "# scoring = ['rmse', 'mae']\n",
    "\n",
    "# #clf1 = KNNWithZScore(verbose=True)\n",
    "# #param1 = {}\n",
    "# #param1['k'] = [50]\n",
    "# #param1['sim_options'] =  {\n",
    "# #                                        'name': ['pearson', 'cosine'],\n",
    "# #                                        'min_support': [1, 5],\n",
    "# #                                        'user_based': [False, True],\n",
    "# #                                    }\n",
    "# #param1['regressor'] = [clf1]\n",
    "# #model_instances.append(clf1)\n",
    "# #params.append(param1)\n",
    "\n",
    "# gs = GridSearchCV(clf1, param1, cv=num_folds, measures=scoring, refit=True,joblib_verbose=2)\n",
    "\n",
    "\n",
    "# gs.fit(traindata)\n",
    "\n",
    "# if Model.KNNWithZScore in model_list:\n",
    "#         clf1 = KNNWithZScore#(verbose=True)\n",
    "#         param1 = {}\n",
    "#         param1['regressor__k'] = [50]\n",
    "#         param1['regressor__sim_options'] =  {\n",
    "#                                                 'name': ['pearson', 'cosine'],\n",
    "#                                                 'min_support': [1, 5],\n",
    "#                                                 'user_based': [False, True],\n",
    "#                                             },\n",
    "#         param1['regressor'] = [clf1]\n",
    "#         model_instances.append(clf1)\n",
    "#         params.append(param1)\n",
    "\n",
    "\n",
    "        \n",
    "# pipeline = Pipeline([('regressor', model_instances[0])])\n",
    "\n",
    "\n",
    "# gs = GridSearchCV(pipeline, params, cv=num_folds, measures=scoring, refit=True,joblib_verbose=2)\n",
    "\n",
    "# gs.fit(traindata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2101db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     \"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "#     #\"min_support\": [3, 4, 5],\n",
    "#     \"user_based\": [False],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model = KNNWithMeans(k=10,sim_options={'name':'pearson' , 'user_based':True})\n",
    "# knn_model.fit(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f747688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy.rmse(test_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Evaluation on testset\n",
    "\n",
    "# test_pred_knn=knn_model.test(testset)\n",
    "\n",
    "# # compute RMSE\n",
    "# accuracy.rmse(test_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790311f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_df = pd.DataFrame(test_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401cfc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_df.sort_values(by=[\"uid\",\"iid\",\"r_ui\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aba7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the famous SVD algorithm.\n",
    "# algo = SVD()\n",
    "\n",
    "# # Run 5-fold cross-validation and print results.\n",
    "# cross_validate(algo, trainset, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c563b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     \"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "#     \"min_support\": [3, 4, 5],\n",
    "#     \"user_based\": [True],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(KNNWithZScore(sim_options=sim_options), traindata, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_result = cross_validate(KNNWithZScore(sim_options=sim_options), trainset, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab62240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# def get_top_n(predictions, n=10):\n",
    "#     # First map the predictions to each user.\n",
    "#     top_n = defaultdict(list)\n",
    "#     for uid, iid, true_r, est, _ in predictions:\n",
    "#         top_n[uid].append((iid, est))\n",
    "\n",
    "#     # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "#     for uid, user_ratings in top_n.items():\n",
    "#         user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "#         top_n[uid] = user_ratings[:n]\n",
    "\n",
    "#     return top_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class collab_filtering_based_recommender_model():\n",
    "#     def __init__(self, model, trainset, testset, data):\n",
    "#         self.model = model\n",
    "#         self.trainset = trainset\n",
    "#         self.testset = testset\n",
    "#         self.data = data\n",
    "#         self.pred_test = None\n",
    "#         self.recommendations = None\n",
    "#         self.top_n = None\n",
    "#         self.recommenddf = None\n",
    "\n",
    "#     def fit_and_predict(self):        \n",
    "#         printmd('**Fitting the train data...**', color='brown')\n",
    "#         self.model.fit(self.trainset)       \n",
    "\n",
    "#         printmd('**Predicting the test data...**', color='brown')\n",
    "#         self.pred_test = self.model.test(self.testset)        \n",
    "#         rmse = round(accuracy.rmse(self.pred_test), 3)\n",
    "#         printmd('**RMSE for the predicted result is ' + str(rmse) + '**', color='brown')   \n",
    "        \n",
    "#         self.top_n = get_top_n(self.pred_test)\n",
    "#         self.recommenddf = pd.DataFrame(columns=['userId', 'productId', 'Rating'])\n",
    "#         for item in self.top_n:\n",
    "#             subdf = pd.DataFrame(self.top_n[item], columns=['productId', 'Rating'])\n",
    "#             subdf['userId'] = item\n",
    "#             cols = subdf.columns.tolist()\n",
    "#             cols = cols[-1:] + cols[:-1]\n",
    "#             subdf = subdf[cols]        \n",
    "#             self.recommenddf = pd.concat([self.recommenddf, subdf], axis = 0)        \n",
    "#         return rmse\n",
    "        \n",
    "#     def cross_validate(self):\n",
    "#         printmd('**Cross Validating the data...**', color='brown')\n",
    "#         cv_result = cross_validate(self.model, self.data, n_jobs=-1)\n",
    "#         cv_result = round(cv_result['test_rmse'].mean(),3)\n",
    "#         printmd('**Mean CV RMSE is ' + str(cv_result)  + '**', color='brown')\n",
    "#         return cv_result\n",
    "\n",
    "#     def recommend(self, user_id, n=5):\n",
    "#         printmd('**Recommending top ' + str(n)+ ' products for userid : ' + user_id + ' ...**', color='brown')\n",
    "        \n",
    "#         #df = pd.DataFrame(self.top_n[user_id], columns=['productId', 'Rating'])\n",
    "#         #df['UserId'] = user_id\n",
    "#         #cols = df.columns.tolist()\n",
    "#         #cols = cols[-1:] + cols[:-1]\n",
    "#         #df = df[cols].head(n)\n",
    "#         df = self.recommenddf[self.recommenddf['userId'] == user_id].head(n)\n",
    "#         display(df)\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from surprise.model_selection import RandomizedSearchCV\n",
    "\n",
    "# def find_best_model(model, parameters,data):\n",
    "#     clf = RandomizedSearchCV(model, parameters, n_jobs=-1, measures=['rmse'])\n",
    "#     clf.fit(data)             \n",
    "#     print(clf.best_score)\n",
    "#     print(clf.best_params)\n",
    "#     print(clf.best_estimator)\n",
    "#     return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d97a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     \"name\": [\"msd\", \"cosine\", \"pearson\", \"pearson_baseline\"],\n",
    "#     \"min_support\": [3, 4, 5],\n",
    "#     \"user_based\": [True],\n",
    "# }\n",
    "# params = { 'k': range(30,50,1), 'sim_options': sim_options}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35965c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = find_best_model(KNNWithZScore, params, trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23d8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
